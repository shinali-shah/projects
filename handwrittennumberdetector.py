# -*- coding: utf-8 -*-
"""handwrittenNumberDetector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rz_Grh4JXp6qxeaYZk08hLl4lxcLih0K
"""

from google.colab import drive
drive.mount('/content/drive')

file_path = '/content/drive/My Drive/numberData/mnist-original.mat' #load in mat file (file with images)

# created a 3 layer CNN
  # input layer: distributes features (catergorization)
  # hidden layer: provides nonlinear ties (to make sure that the accuracy is higher, this checks for more intricate patterns within the data)
  # output layer: final prediction of what number was written in the image

"""

```
# This is formatted as code
```

#RandInitialize.py"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile RandomInitialize.py
# import numpy as np #import the method that allows for all the mathematical calcs
# 
# def initialise(a, b):
#     epsilon = 0.15 #establishes the weights, the weights are the factor that you multiply your calculations by, the weights get adjusted as the model learns
#     c = np.random.rand(a, b + 1) * (
#       # creates a range for weights
#       2 * epsilon) - epsilon
#     return c
#

"""#Model.py

1.   List item
2.   List item


"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile Model.py
# import numpy as np
# 
# 
# def neural_network(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lamb):
#     # two weights:
#     Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],
#                         (hidden_layer_size, input_layer_size + 1))
#     Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):],
#                         (num_labels, hidden_layer_size + 1))
# 
#     # Forward propagation AKA data being fed in; calculating for bias (if the training dataset is skewed with more of one type of number)
#     m = X.shape[0]
#     one_matrix = np.ones((m, 1))
#     X = np.append(one_matrix, X, axis=1)  # Adding bias unit to first layer
#     a1 = X
#     z2 = np.dot(X, Theta1.transpose())
#     a2 = 1 / (1 + np.exp(-z2))  # Activation for second layer
#     one_matrix = np.ones((m, 1))
#     a2 = np.append(one_matrix, a2, axis=1)  # Adding bias unit to hidden layer
#     z3 = np.dot(a2, Theta2.transpose())
#     a3 = 1 / (1 + np.exp(-z3))  # Activation for third layer
# 
#     # Changing the y labels into vectors of boolean values; splits up the image to read the colors (boolean values: white and black get assigned to true/false)
#     y_vect = np.zeros((m, 10))
#     for i in range(m):
#         y_vect[i, int(y[i])] = 1
#     J = (1 / m) * (np.sum(np.sum(-y_vect * np.log(a3) - (1 - y_vect) * np.log(1 - a3)))) + (lamb / (2 * m)) * (
#                 sum(sum(pow(Theta1[:, 1:], 2))) + sum(sum(pow(Theta2[:, 1:], 2))))
# 
#     # backprop
#     Delta3 = a3 - y_vect # gets the error between the actual vector value and the predicted value; adjusts the weights in the layers
#     Delta2 = np.dot(Delta3, Theta2) * a2 * (1 - a2) #this adjusts the weights in the layers --> adjusts w/ bias
#     Delta2 = Delta2[:, 1:]  #removes the bias calculations
# 
#     # gradient
#     Theta1[:, 0] = 0 #weight matrix btwn input and hidden layers (cnn --> diff layers, input/hidden/output)
#     Theta1_grad = (1 / m) * np.dot(Delta2.transpose(), a1) + (lamb / m) * Theta1
#     Theta2[:, 0] = 0 #makes sure that the bias weights wont be regulized
#     Theta2_grad = (1 / m) * np.dot(Delta3.transpose(), a2) + (lamb / m) * Theta2
#     grad = np.concatenate((Theta1_grad.flatten(), Theta2_grad.flatten()))
# 
#     return J, grad
#

"""#Prediction.py"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile Prediction.py
# import numpy as np
# 
# 
# def predict(Theta1, Theta2, X):
#     m = X.shape[0]
#     one_matrix = np.ones((m, 1))
#     X = np.append(one_matrix, X, axis=1)  # Adding bias unit to first layer
#     z2 = np.dot(X, Theta1.transpose())
#     a2 = 1 / (1 + np.exp(-z2))  # Activates for second layer
#     one_matrix = np.ones((m, 1))
#     a2 = np.append(one_matrix, a2, axis=1)  # Adding bias unit to hidden layer
#     z3 = np.dot(a2, Theta2.transpose())
#     a3 = 1 / (1 + np.exp(-z3))  # Activates third layer
#     p = (np.argmax(a3, axis=1))  # Predicting the class on the basis of max value of hypothesis
#     return p
#

"""#GUI.py"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile GUI.py
# from tkinter import *
# import numpy as np
# from PIL import ImageGrab
# from Prediction import predict
# 
# window = Tk()
# window.title("Handwritten digit recognition")
# l1 = Label()
# 
# 
# def MyProject():
#     global l1
# 
#     widget = cv
#     # Setting the coordinates
#     x = window.winfo_rootx() + widget.winfo_x()
#     y = window.winfo_rooty() + widget.winfo_y()
#     x1 = x + widget.winfo_width()
#     y1 = y + widget.winfo_height()
# 
#     # Image is captured from canvas and is resized to (28 X 28) px
#     img = ImageGrab.grab().crop((x, y, x1, y1)).resize((28, 28))
# 
#     # Converting rgb to grayscale
#     img = img.convert('L')
# 
#     # Extracting pixel matrix of image and converting it to a vector of (1, 784)
#     x = np.asarray(img)
#     vec = np.zeros((1, 784))
#     k = 0
#     for i in range(28):
#         for j in range(28):
#             vec[0][k] = x[i][j]
#             k += 1
# 
#     Theta1 = np.loadtxt('Theta1.txt')
#     Theta2 = np.loadtxt('Theta2.txt')
# 
#     pred = predict(Theta1, Theta2, vec / 255)
# 
#     l1 = Label(window, text="Digit = " + str(pred[0]), font=('Algerian', 20))
#     l1.place(x=230, y=420)
# 
# 
# lastx, lasty = None, None
# 
# 
# def clear_widget():
#     global cv, l1
#     cv.delete("all")
#     l1.destroy()
# def event_activation(event):
#     global lastx, lasty
#     cv.bind('<B1-Motion>', draw_lines)
#     lastx, lasty = event.x, event.y
# 
# 
# # To draw on canvas
# def draw_lines(event):
#     global lastx, lasty
#     x, y = event.x, event.y
#     cv.create_line((lastx, lasty, x, y), width=30, fill='white', capstyle=ROUND, smooth=TRUE, splinesteps=12)
#     lastx, lasty = x, y
# 
# 
# L1 = Label(window, text="Handwritten Digit Recoginition", font=('Algerian', 25), fg="blue")
# L1.place(x=35, y=10)
# 
# b1 = Button(window, text="1. Clear Canvas", font=('Algerian', 15), bg="orange", fg="black", command=clear_widget)
# b1.place(x=120, y=370)
# 
# b2 = Button(window, text="2. Prediction", font=('Algerian', 15), bg="white", fg="red", command=MyProject)
# b2.place(x=320, y=370)
# 
# cv = Canvas(window, width=350, height=290, bg='black')
# cv.place(x=120, y=70)
# 
# cv.bind('<Button-1>', event_activation)
# window.geometry("600x500")
# window.mainloop()
#

from scipy.io import loadmat
import numpy as np
from Model import neural_network
from RandInitialize import initialise
from Prediction import predict
from scipy.optimize import minimize



data = loadmat('/content/drive/My Drive/numberData/mnist-original.mat') #talk ab how i ran into an error here

X = data['data']
X = X.transpose()

X = X / 255

y = data['label']
y = y.flatten()

X_train = X[:60000, :] #splits data
y_train = y[:60000]

X_test = X[60000:, :]
y_test = y[60000:]
m = X.shape[0]
input_layer_size = 784  # sets the layer features to 784 bc the images are 28 by 28
hidden_layer_size = 100
num_labels = 10  # There are 10 classes [0, 9]

initial_Theta1 = initialise(hidden_layer_size, input_layer_size)
initial_Theta2 = initialise(num_labels, hidden_layer_size)

initial_nn_params = np.concatenate((initial_Theta1.flatten(), initial_Theta2.flatten()))
maxiter = 100
lambda_reg = 0.1  # To avoid overfitting
myargs = (input_layer_size, hidden_layer_size, num_labels, X_train, y_train, lambda_reg)

results = minimize(neural_network, x0=initial_nn_params, args=myargs,
          options={'disp': True, 'maxiter': maxiter}, method="L-BFGS-B", jac=True)

nn_params = results["x"]  # Trained Theta is extracted

Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)], (
                              hidden_layer_size, input_layer_size + 1))  # shape = (100, 785)
Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):],
                      (num_labels, hidden_layer_size + 1))  # shape = (10, 101)

pred = predict(Theta1, Theta2, X_test)
print('Test Set Accuracy: {:f}'.format((np.mean(pred == y_test) * 100)))

pred = predict(Theta1, Theta2, X_train)
print('Training Set Accuracy: {:f}'.format((np.mean(pred == y_train) * 100)))

true_positive = 0
for i in range(len(pred)):
    if pred[i] == y_train[i]:
        true_positive += 1
false_positive = len(y_train) - true_positive
print('Precision =', true_positive/(true_positive + false_positive))

np.savetxt('Theta1.txt', Theta1, delimiter=' ')
np.savetxt('Theta2.txt', Theta2, delimiter=' ')